"""
Test RÃ¡pido - Ambos Modelos Azure OpenAI
Prueba rÃ¡pida de GPT-4o y o3-mini
"""

import asyncio
from dotenv import load_dotenv

load_dotenv()

async def test_both_models_quick():
    """Test rÃ¡pido de ambos modelos"""
    
    try:
        from agents.infrastructure_agents.services.azure_openai_service import AzureOpenAIService, OpenAIRequest
        from agents.infrastructure_agents.config.azure_config import AzureOpenAIConfig
        from datetime import datetime
        
        print("ğŸ§ª Quick Test - Both Models")
        print("=" * 40)
        
        # Load config
        config = AzureOpenAIConfig.from_env()
        service = AzureOpenAIService(config)
        
        print(f"ğŸ“ Endpoint: {config.endpoint}")
        print(f"ğŸ¤– GPT-4o: {config.deployment_name}")
        print(f"âš¡ o3-mini: {config.deployment_name_mini}")
        
        # Test data
        test_data = {"company": "Test Corp", "revenue": 100000}
        
        # Test 1: GPT-4o
        print(f"\nğŸ§  Testing GPT-4o...")
        gpt4o_request = OpenAIRequest(
            request_id="test_gpt4o",
            user_id="system",
            agent_id="test",
            prompt=f"Analyze this company briefly: {test_data}",
            max_tokens=200,
            temperature=0.3,
            timestamp=datetime.now()
        )
        
        gpt4o_response = await service.generate_completion(
            gpt4o_request, 
            "You are a financial analyst. Be concise.",
            use_mini_model=False
        )
        
        print(f"âœ… GPT-4o Success!")
        print(f"ğŸ¯ Tokens: {gpt4o_response.tokens_used}")
        print(f"ğŸ“ Response: {gpt4o_response.response_text[:100]}...")
        
        # Test 2: o3-mini
        print(f"\nâš¡ Testing o3-mini...")
        o3mini_request = OpenAIRequest(
            request_id="test_o3mini",
            user_id="system", 
            agent_id="test",
            prompt=f"Validate this data quickly: {test_data}",
            max_tokens=100,
            temperature=0.1,
            timestamp=datetime.now()
        )
        
        o3mini_response = await service.generate_completion(
            o3mini_request,
            "You are a data validator. Be brief.",
            use_mini_model=True
        )
        
        print(f"âœ… o3-mini Success!")
        print(f"ğŸ¯ Tokens: {o3mini_response.tokens_used}")
        print(f"ğŸ“ Response: {o3mini_response.response_text[:100]}...")
        
        print(f"\nğŸ‰ Both models working perfectly!")
        print(f"ğŸ’° Cost optimization: o3-mini for quick tasks")
        print(f"ğŸ§  Quality analysis: GPT-4o for complex tasks")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(test_both_models_quick())
    if success:
        print("\nâœ… DUAL MODELS READY FOR PRODUCTION!")
    else:
        print("\nâŒ Fix configuration and try again")